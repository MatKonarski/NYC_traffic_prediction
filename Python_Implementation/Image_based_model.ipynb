{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6ad393a-b5c4-4709-a165-4b23f2c4b1f3",
   "metadata": {},
   "source": [
    "Author: **Mathis Konarski** </br>\n",
    "Date: **21/06/2022**\n",
    "\n",
    "This notebook implement an image based model on NYC bike and NYC taxi data. </br>\n",
    "The model idea is based on *Revisiting Spatial-Temporal Similarity: A Deep Learning Framework for Traffic Prediction* by H. Yao, X. Tang, H. Wei, G. Zheng and Z. Li. </br>\n",
    "However there is implementation differences and this model is not including an attention layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d7b83e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "import Training_functions as t_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81deb4aa-ebdf-44b4-a2aa-9d422996bb45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "GRID_SIZE = (10, 20)\n",
    "TRAIN_PERIOD = 70*24*2 # TIME_PERIOD\n",
    "BATCH_SIZE = 4\n",
    "WINDOW_SIZE = 3*24*2 # TIME_PERIOD\n",
    "MIN_VOL_METRICS = 10\n",
    "MIN_FLOW = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d786716c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Visualization volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ef0606",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def volume_show(period):\n",
    "    train_period_df = train_df[train_df.period==period]\n",
    "    start = np.zeros((20,10))\n",
    "    stop = np.zeros((20,10))\n",
    "    for i in train_period_df.lat.unique():\n",
    "        lat_period_df = train_period_df[train_period_df.lat==i]\n",
    "        for j in lat_period_df.lon.unique():\n",
    "            start[j-1,i-1] = lat_period_df[lat_period_df.lon==j].volume_start\n",
    "            stop[j-1,i-1] = lat_period_df[lat_period_df.lon==j].volume_stop\n",
    "\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    ax1.axis('off')\n",
    "    ax2.axis('off')\n",
    "    ax1.matshow(start, vmin=0, vmax=350, cmap='gist_stern', origin='lower')\n",
    "    ax2.matshow(stop, vmin=0, vmax=350, cmap='gist_stern', origin='lower')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae45c79-ecbf-4df3-97e5-ea046c95843e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6903a421-438a-4c5f-b7ea-95f968ed0991",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_df = pd.read_csv(\"Datasets/ytaxi_prepared.csv\", index_col=0)\n",
    "data_flow_np = t_func.flow_data(data_df, GRID_SIZE, MIN_FLOW)\n",
    "data_vol_np = t_func.volume_data(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d824d2-aefb-4ebc-bf7a-609047bb5db9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TimeSeriesDataset(torch.utils.data.Dataset):\n",
    "    '''\n",
    "    Custome pyTorch datasets in order to handle time series data with flow and volume information\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_vol_ten : torch tensor with start and end volume for each period and area\n",
    "    data_flow_lst : list of flow graphs\n",
    "    window : length of previous data considered for LSTM\n",
    "    norm_y : maximal volume value for the training set\n",
    "    '''\n",
    "    def __init__(self, data_vol_ten, data_flow_ten, window, norm_y):\n",
    "        self.data_vol = data_vol_ten\n",
    "        self.data_flow = data_flow_ten\n",
    "        self.window = window\n",
    "        self.norm_y = norm_y\n",
    "        self.shape = self.__getshape__()\n",
    "        self.size = self.__getsize__()\n",
    " \n",
    "    def __getitem__(self, index):\n",
    "        index = index\n",
    "        v = self.data_vol[index:index+self.window]\n",
    "        f = self.data_flow[index:index+self.window]\n",
    "        y = self.data_vol[index+1:index+self.window+1]/self.norm_y\n",
    "        return v, f, y\n",
    " \n",
    "    def __len__(self):\n",
    "        return len(self.data_vol) -  self.window\n",
    "    \n",
    "    def __getshape__(self):\n",
    "        return (self.__len__(), *self.__getitem__(0)[0].shape)\n",
    "    \n",
    "    def __getsize__(self):\n",
    "        return (self.__len__())\n",
    "\n",
    "def create_dataloader(flow_np, vol_np, train_period, batch_size, window_size):\n",
    "    '''\n",
    "    Create pyTorch DataLoader for train and test data based on TimeSeriesDataset\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    flow_np : flow informations based on flow_data function\n",
    "    vol_np : volume informations based on volume_data function\n",
    "    train_period : length of the training period\n",
    "    batch_size\n",
    "    window_size : length of previous data considered for LSTM\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    train_dataloader pytorch_geometic.loader.DataLoader\n",
    "    test_dataloader pytorch_geometic.loader.DataLoader\n",
    "    norm_y : maximal volume value for the training set\n",
    "    '''\n",
    "    norm_y = vol_np[:train_period].max()\n",
    "    train_dataset = TimeSeriesDataset(torch.Tensor(vol_np[:train_period]),\n",
    "                                      torch.tensor(flow_np[:train_period], dtype=torch.uint8),\n",
    "                                      window_size, norm_y)\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    test_dataset = TimeSeriesDataset(torch.Tensor(vol_np[train_period-window_size:]),\n",
    "                                     torch.tensor(flow_np[train_period-window_size:], dtype=torch.uint8),\n",
    "                                     window_size, norm_y)\n",
    "    test_dataloader = torch.utils.data.DataLoader(test_dataset)\n",
    "    return train_dataloader, test_dataloader, norm_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4370ab7c-4d92-4ed4-b55c-9018885f5fa9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loader, test_loader, norm_y = create_dataloader(data_flow_np, data_vol_np, TRAIN_PERIOD,\n",
    "                                                      BATCH_SIZE, WINDOW_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e21d3a-9d48-4b0d-aba0-7b7befd05c97",
   "metadata": {
    "tags": []
   },
   "source": [
    "# PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd6d746-45d5-4fb4-b68f-a969aa667a6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd339b7b-0060-4517-8eb7-167620c1b48f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class YaoNeuralNetwork(nn.Module):\n",
    "    def __init__(self, norm):\n",
    "        super(YaoNeuralNetwork, self).__init__()\n",
    "        self.dropout_rate = 0.5 \n",
    "        self.conv_vol_size = 2\n",
    "        self.in_flow_size = 2\n",
    "        self.conv_flow_size = 2\n",
    "        self.out_flow_vol_size = 4\n",
    "        self.lstm_input_size = 4\n",
    "        self.lstm_output_size = 32\n",
    "        self.norm = norm\n",
    "        \n",
    "        self.norm_vol = nn.BatchNorm3d(WINDOW_SIZE)\n",
    "        self.conv_vol = nn.Sequential(\n",
    "            nn.Conv3d(2, self.conv_vol_size, (1,3,3)), nn.ReLU(),\n",
    "            nn.Conv3d(self.conv_vol_size, self.conv_vol_size, (1,3,3)), nn.ReLU(),\n",
    "            nn.Conv3d(self.conv_vol_size, self.conv_vol_size, (1,3,3)), nn.ReLU() )\n",
    "        self.dense_vol = nn.Sequential(\n",
    "            nn.Flatten(2), nn.Dropout(self.dropout_rate), nn.Linear(self.conv_vol_size*4*14, self.out_flow_vol_size), nn.ReLU() )\n",
    "        \n",
    "        self.norm_flow = nn.Sequential(\n",
    "            nn.Flatten(4), nn.Linear(200, self.in_flow_size), nn.ReLU(), nn.BatchNorm3d(WINDOW_SIZE) )\n",
    "        self.conv_flow = nn.Sequential(\n",
    "            nn.Conv3d(self.in_flow_size, self.conv_flow_size, (1,3,3)), nn.ReLU(),\n",
    "            nn.Conv3d(self.conv_flow_size, self.conv_flow_size, (1,3,3)), nn.ReLU(),\n",
    "            nn.Conv3d(self.conv_flow_size, self.conv_flow_size, (1,3,3)), nn.ReLU() )\n",
    "        self.dense_flow = nn.Sequential(\n",
    "            nn.Flatten(2), nn.Dropout(self.dropout_rate), nn.Linear(self.conv_flow_size*56, self.out_flow_vol_size), nn.ReLU() )\n",
    "        \n",
    "        self.pre_lstm = nn.Sequential(\n",
    "            nn.Dropout(0.5), nn.Linear(self.out_flow_vol_size, self.lstm_input_size), nn.ReLU() )\n",
    "        self.lstm = nn.LSTM(input_size=self.lstm_input_size, hidden_size=self.lstm_output_size, num_layers=1, dropout=0, batch_first=True)\n",
    "        self.end = nn.Sequential(\n",
    "            nn.Dropout(self.dropout_rate), nn.Linear(self.lstm_output_size, 400), nn.Tanh(),\n",
    "            nn.Unflatten(2, (10,20,2)) )\n",
    "\n",
    "    def forward(self, v, f):\n",
    "        v = self.norm_vol(v)\n",
    "        v = self.conv_vol(v.permute(0,4,1,2,3))\n",
    "        v = self.dense_vol(v.permute(0,2,3,4,1))\n",
    "        f = self.norm_flow(f/self.norm)\n",
    "        f = self.conv_flow(f.permute(0,4,1,2,3))\n",
    "        f = self.dense_flow(f.permute(0,2,3,4,1))\n",
    "        x = torch.mul(v,f)\n",
    "        x = self.pre_lstm(x)\n",
    "        (h0, c0) = (torch.zeros(1,x.shape[0], self.lstm_output_size), torch.zeros(1,x.shape[0], self.lstm_output_size))\n",
    "        (x, (_, _)) = self.lstm(x, (h0, c0))\n",
    "        logits = self.end(x)\n",
    "        return logits\n",
    "    \n",
    "YaoModel = YaoNeuralNetwork().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe15d56f-2a0e-4774-8899-3751b9a90a01",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = YaoModel\n",
    "loader_tuple = (train_loader, test_loader, norm_y)\n",
    "loss_mse = torch.nn.MSELoss(reduction='none')\n",
    "epochs = 100\n",
    "patience=5\n",
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate , eps=1e-7) # ADAM # RMSprop etc..\n",
    "\n",
    "                \n",
    "t_func.model_training(loader_tuple, model, loss_mse, optimizer, epochs, MIN_VOL_METRICS, patience)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f9f967db-48ae-44c4-8e1b-79d093585299",
   "metadata": {},
   "source": [
    "Model parameters and scoring\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "TIME_PERIOD = 30*60\n",
    "WINDOW_SIZE = 3*24*2\n",
    "dropout_rate = 0.5\n",
    "conv_vol_size = 2\n",
    "in_flow_size = 2\n",
    "conv_flow_size = 4\n",
    "out_flow_vol_size = 4\n",
    "lstm_input_size = 4\n",
    "lstm_output_size = 32\n",
    "\n",
    "bike:\n",
    "        \n",
    "Epoch 5:\n",
    "\n",
    "100%|████████████████████████████████████████████████████████████████████████████████| 804/804 [02:17<00:00,  5.84it/s]\n",
    "\n",
    "Train : Avg loss: 0.000180 | Start RMSE: 8.23 | Start MAPE: 27.42 % | Stop RMSE: 7.81 | Stop MAPE: 26.87 %\n",
    "Test : Avg loss: 0.000356 | Start RMSE: 9.26 | Start MAPE: 26.19 % | Stop RMSE: 9.12 | Stop MAPE: 25.81 %\n",
    "\n",
    "\n",
    "ytaxi:\n",
    "\n",
    "Epoch 10:\n",
    "\n",
    "100%|████████████████████████████████████████████████████████████████████████████████| 804/804 [02:24<00:00,  5.58it/s]\n",
    "\n",
    "Train : Avg loss: 0.000372 | Start RMSE: 29.72 | Start MAPE: 34.13 % | Stop RMSE: 25.21 | Stop MAPE: 32.33 %\n",
    "Test : Avg loss: 0.000475 | Start RMSE: 30.75 | Start MAPE: 38.11 % | Stop RMSE: 27.42 | Stop MAPE: 37.23 %\n",
    "\n",
    "\n",
    "gtaxi:\n",
    "\n",
    "Epoch 11:\n",
    "\n",
    "100%|████████████████████████████████████████████████████████████████████████████████| 804/804 [02:31<00:00,  5.30it/s]\n",
    "\n",
    "Train : Avg loss: 0.000092 | Start RMSE: 6.52 | Start MAPE: 27.88 % | Stop RMSE: 3.45 | Stop MAPE: 19.43 %\n",
    "Test : Avg loss: 0.000056 | Start RMSE: 6.33 | Start MAPE: 30.91 % | Stop RMSE: 3.04 | Stop MAPE: 20.13 %"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Aucun(e)",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
