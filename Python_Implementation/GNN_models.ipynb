{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb1c5c65-3076-4b6a-9566-9654f6c816d8",
   "metadata": {},
   "source": [
    "Author: **Mathis Konarski** </br>\n",
    "Date: **22/06/2022**\n",
    "\n",
    "This notebook implement a GNN model on NYC bike and NYC taxi data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1489ad4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch import nn\n",
    "import torch\n",
    "import torch_geometric as tog\n",
    "from torch_geometric import nn as tog_nn\n",
    "\n",
    "import Training_functions as t_func\n",
    "\n",
    "import gc\n",
    "gc.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c91b27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "GRID_SIZE = (10, 20) # /!\\ Must be the same than used inside Data_Preparation.ipynb\n",
    "TRAIN_PERIOD = 70*24*2 # time_period defined inside Data_Preparation.ipynb as 30 minutes\n",
    "BATCH_SIZE = 4 # batch size for the deep learning model\n",
    "WINDOW_SIZE = 3*24*2 # time_period defined inside Data_Preparation.ipynb as 30 minutes\n",
    "MIN_VOL_METRICS = 10 # Minimal demand for one area volume to be considered during evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2901e273-c752-4508-824a-7c888ced8f03",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Flow and Volume creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1753d262-65de-43a9-ab7b-1d170260a380",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_ytaxi_df = pd.read_csv(\"Datasets/ytaxi_prepared.csv\", index_col=0)\n",
    "data_gtaxi_df = pd.read_csv(\"Datasets/gtaxi_prepared.csv\", index_col=0)\n",
    "data_bike_df = pd.read_csv(\"Datasets/bike_prepared.csv\", index_col=0) # Read the data transformed using Data_Preparation.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7b0915-3235-43e4-b27f-71453a56a9f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bike_graph_flow_ser = t_func.flow_graphs(data_bike_df, GRID_SIZE)\n",
    "ytaxi_graph_flow_ser = t_func.flow_graphs(data_ytaxi_df, GRID_SIZE)\n",
    "gtaxi_graph_flow_ser = t_func.flow_graphs(data_gtaxi_df, GRID_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3832668-63c5-4e7f-94a9-4f1420567ac8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bike_vol_np = t_func.volume_data(data_bike_df)\n",
    "ytaxi_vol_np = t_func.volume_data(data_ytaxi_df)\n",
    "gtaxi_vol_np = t_func.volume_data(data_gtaxi_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d193bf01-93ea-43bc-9bad-6e445451c2f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TimeSeriesDataset(torch.utils.data.Dataset):\n",
    "    '''\n",
    "    Custome pyTorch datasets in order to handle time series data with flow and volume information\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_vol_ten : torch tensor with start and end volume for each period and area\n",
    "    data_flow_lst : list of flow graphs\n",
    "    window : length of previous data considered for LSTM\n",
    "    norm_y : maximal volume value for the training set\n",
    "    '''\n",
    "    def __init__(self, data_vol_ten, data_flow_lst, window, norm_y):\n",
    "        self.data_vol = data_vol_ten\n",
    "        self.data_flow = data_flow_lst\n",
    "        self.window = window\n",
    "        self.norm_y = norm_y\n",
    "        self.shape = self.__getshape__()\n",
    "        self.size = self.__getsize__()\n",
    " \n",
    "    def __getitem__(self, index):\n",
    "        v = self.data_vol[index:index+self.window]\n",
    "        f = self.data_flow[index:index+self.window]\n",
    "        y = self.data_vol[index+1:index+self.window+1]/self.norm_y\n",
    "        return v, f, y\n",
    " \n",
    "    def __len__(self):\n",
    "        return len(self.data_vol) -  self.window \n",
    "    \n",
    "    def __getshape__(self):\n",
    "        return (self.__len__(), *self.__getitem__(0)[0].shape)\n",
    "    \n",
    "    def __getsize__(self):\n",
    "        return (self.__len__())\n",
    "    \n",
    "\n",
    "def create_dataloader(flow_ser, vol_np, train_period, batch_size, window_size):\n",
    "    '''\n",
    "    Create pyTorch DataLoader for train and test data based on TimeSeriesDataset\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    flow_ser : flow informations based on flow_graphs function\n",
    "    vol_np : volume informations based on volume_data function\n",
    "    train_period : length of the training period\n",
    "    batch_size\n",
    "    window_size : length of previous data considered for LSTM\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    train_dataloader pytorch_geometic.loader.DataLoader\n",
    "    test_dataloader pytorch_geometic.loader.DataLoader\n",
    "    norm_y : maximal volume value for the training set\n",
    "    '''\n",
    "    norm_y = vol_np[:train_period].max()\n",
    "    train_dataset = TimeSeriesDataset(torch.Tensor(vol_np[:train_period]),\n",
    "                                      list(flow_ser[:train_period]), window_size, norm_y)\n",
    "    train_dataloader = tog.loader.DataLoader(train_dataset, batch_size=batch_size, shuffle = True)\n",
    "\n",
    "    test_dataset = TimeSeriesDataset(torch.Tensor(vol_np[train_period-window_size:]),\n",
    "                                     list(flow_ser[train_period-window_size:]), window_size, norm_y)\n",
    "    test_dataloader = tog.loader.DataLoader(test_dataset)\n",
    "    return train_dataloader, test_dataloader, norm_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbf1478-ecc4-4228-8254-e38c97a88fb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bike_train_loader, bike_test_loader, bike_norm_y = create_dataloader(bike_graph_flow_ser, bike_vol_np, TRAIN_PERIOD, BATCH_SIZE, WINDOW_SIZE)\n",
    "gtaxi_train_loader, gtaxi_test_loader, gtaxi_norm_y = create_dataloader(gtaxi_graph_flow_ser, gtaxi_vol_np, TRAIN_PERIOD, BATCH_SIZE, WINDOW_SIZE)\n",
    "ytaxi_train_loader, ytaxi_test_loader, ytaxi_norm_y = create_dataloader(ytaxi_graph_flow_ser, ytaxi_vol_np, TRAIN_PERIOD, BATCH_SIZE, WINDOW_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e285a924-440d-431a-bb61-29a76603aa10",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80166855-efbc-4586-8990-8a626606d3e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b18392f-44af-4701-a44d-870a9043e715",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GnnNeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GnnNeuralNetwork, self).__init__()\n",
    "        self.dropout_rate = 0.5\n",
    "        self.conv_vol_size = 2\n",
    "        self.conv_flow_size = 4\n",
    "        self.out_flow_vol_size = 4\n",
    "        self.lstm_input_size = 4\n",
    "        self.lstm_output_size = 32\n",
    "        \n",
    "        self.norm_vol = nn.BatchNorm3d(WINDOW_SIZE)\n",
    "        self.conv_vol = nn.Sequential(\n",
    "            nn.Conv3d(2, self.conv_vol_size, (1,3,3)), nn.ReLU(),\n",
    "            nn.Conv3d(self.conv_vol_size, self.conv_vol_size, (1,3,3)), nn.ReLU(),\n",
    "            nn.Conv3d(self.conv_vol_size, self.conv_vol_size, (1,3,3)), nn.ReLU() )\n",
    "        self.dense_vol = nn.Sequential(\n",
    "            nn.Flatten(2), nn.Dropout(self.dropout_rate), nn.Linear(self.conv_vol_size*4*14, self.out_flow_vol_size), nn.ReLU() )\n",
    "        \n",
    "        self.conv_flow = tog_nn.GCN(1, hidden_channels = self.conv_flow_size , num_layers=3, act='relu')\n",
    "        self.dense_flow = nn.Sequential(\n",
    "            nn.BatchNorm1d(WINDOW_SIZE),\n",
    "            nn.Dropout(self.dropout_rate), nn.Linear(200*self.conv_flow_size, self.out_flow_vol_size), nn.ReLU() )\n",
    "        \n",
    "        self.pre_lstm = nn.Sequential(\n",
    "            nn.Dropout(self.dropout_rate), nn.Linear(self.out_flow_vol_size,self.lstm_input_size), nn.ReLU() )\n",
    "        self.lstm = nn.LSTM(input_size=self.lstm_input_size, hidden_size=self.lstm_output_size, num_layers=1, dropout=0, batch_first=True)\n",
    "        self.end = nn.Sequential(\n",
    "            nn.Dropout(self.dropout_rate), nn.Linear(self.lstm_output_size, 400), nn.Tanh(),\n",
    "            nn.Unflatten(2, (10,20,2)) )\n",
    "\n",
    "    def forward(self, v, f):\n",
    "        v = self.norm_vol(v)\n",
    "        v = self.conv_vol(v.permute(0,4,1,2,3))\n",
    "        v = self.dense_vol(v.permute(0,2,3,4,1))\n",
    "        n_batches = len(f[0].ptr)-1\n",
    "        f_nodes = torch.empty((len(f), n_batches, 200 * self.conv_flow_size), dtype=torch.float)\n",
    "        for i in range(len(f)):\n",
    "            f[i].x = self.conv_flow(f[i].x, f[i].edge_index, f[i].edge_weight)\n",
    "            f_nodes[i] = nn.Flatten(1)(f[i].x.reshape(n_batches,200,self.conv_flow_size))\n",
    "        f = torch.reshape(f_nodes, (WINDOW_SIZE, n_batches, 200*self.conv_flow_size))\n",
    "        f = torch.permute(f, (1, 0, 2))\n",
    "        f = self.dense_flow(f)\n",
    "        x = torch.mul(v,f)\n",
    "        x = self.pre_lstm(x)\n",
    "        (h0, c0) = (torch.zeros(1,x.shape[0], self.lstm_output_size), torch.zeros(1,x.shape[0], self.lstm_output_size))\n",
    "        (x, (_, _)) = self.lstm(x)\n",
    "        logits = self.end(x)\n",
    "        return logits\n",
    "    \n",
    "GNNmodel = GnnNeuralNetwork().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3df35f-dfb2-4c57-9351-3bbbd99cf985",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = GNNmodel\n",
    "loader_tuple = bike_train_loader, bike_test_loader, bike_norm_y\n",
    "loss_mse = torch.nn.MSELoss(reduction='none')\n",
    "learning_rate = 6e-4\n",
    "epochs = 100\n",
    "patience=5\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate , eps=1e-7)\n",
    "\n",
    "t_func.model_training(loader_tuple, model, loss_mse, optimizer, epochs, MIN_VOL_METRICS, patience=5)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ae8aac81-b6a9-476b-9cc5-26992d4fc65f",
   "metadata": {},
   "source": [
    "Model parameters and scoring\n",
    "\n",
    "TIME_PERIOD = 30*60\n",
    "WINDOW_SIZE = 3*24*2\n",
    "dropout_rate = 0.5\n",
    "conv_vol_size = 2\n",
    "conv_flow_size = 4\n",
    "out_flow_vol_size = 4\n",
    "lstm_input_size = 4\n",
    "lstm_output_size = 32\n",
    "\n",
    "\n",
    "\n",
    "Bike: lr = 6e-4\n",
    "\n",
    "Epoch 13:\n",
    "\n",
    "100%|████████████████████████████████████████████████████████████████████████████████| 804/804 [09:33<00:00,  1.40it/s]\n",
    "\n",
    "Train : Avg loss: 0.000250 | Start RMSE: 8.34 | Start MAPE: 27.89 % | Stop RMSE: 7.96 | Stop MAPE: 26.96 %\n",
    "Test : Avg loss: 0.000369 | Start RMSE: 9.38 | Start MAPE: 25.73 % | Stop RMSE: 8.98 | Stop MAPE: 24.90 %\n",
    "\n",
    "\n",
    "\n",
    "ytaxi: lr = 1e-3 not perfect\n",
    "\n",
    "Epoch 11:\n",
    "\n",
    "100%|████████████████████████████████████████████████████████████████████████████████| 804/804 [17:22<00:00,  1.30s/it]\n",
    "\n",
    "Train : Avg loss: 0.000451 | Start RMSE: 30.17 | Start MAPE: 34.01 % | Stop RMSE: 25.59 | Stop MAPE: 32.21 %\n",
    "Test : Avg loss: 0.000454 | Start RMSE: 30.32 | Start MAPE: 36.70 % | Stop RMSE: 26.24 | Stop MAPE: 36.23 %\n",
    "\n",
    "\n",
    "\n",
    "gtaxi: lr = 2e-3\n",
    "\n",
    "Epoch 8:\n",
    "\n",
    "100%|████████████████████████████████████████████████████████████████████████████████| 804/804 [08:57<00:00,  1.50it/s]\n",
    "\n",
    "Train : Avg loss: 0.000042 | Start RMSE: 5.81 | Start MAPE: 25.11 % | Stop RMSE: 3.38 | Stop MAPE: 19.10 %\n",
    "Test : Avg loss: 0.000053 | Start RMSE: 6.00 | Start MAPE: 27.75 % | Stop RMSE: 2.97 | Stop MAPE: 19.51 %"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caea017e-114d-41c8-aa01-91da052ce178",
   "metadata": {},
   "source": [
    "# Combined training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af5a2f3-b14c-4f84-a3bd-45cad056f1c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class InterModalityCombiner(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(InterModalityCombiner, self).__init__()\n",
    "        self.dropout_rate = 0.5\n",
    "        self.hid_layer_size = 64\n",
    "        self.dense_layer = nn.Sequential(\n",
    "            nn.Flatten(2), nn.Dropout(self.dropout_rate), nn.Linear(3*400, self.hid_layer_size), nn.ReLU(),\n",
    "            nn.Linear(self.hid_layer_size, 3*400), nn.Tanh(), nn.Unflatten(2, (3, 10, 20, 2))  )\n",
    "\n",
    "    def forward(self, m1, m2, m3):\n",
    "        x = torch.concat((m1, m2, m3), axis=2)\n",
    "        logits = self.dense_layer(x)\n",
    "        return logits.permute(2, 0, 1, 3, 4, 5)\n",
    "    \n",
    "IMCNmodel = InterModalityCombiner().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d257ee-9df2-4452-af38-e1bb7d19104c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loaders_tuple = bike_train_loader, gtaxi_train_loader, ytaxi_train_loader\n",
    "test_loaders_tuple = bike_test_loader, gtaxi_test_loader, ytaxi_test_loader\n",
    "norms_tuple = bike_norm_y, gtaxi_norm_y, ytaxi_norm_y\n",
    "GNN_models_tuple = (GnnNeuralNetwork().to(device),\n",
    "                    GnnNeuralNetwork().to(device),\n",
    "                    GnnNeuralNetwork().to(device))\n",
    "combined_model = InterModalityCombiner().to(device)\n",
    "loss_mse = torch.nn.MSELoss(reduction='none')\n",
    "epochs = 30\n",
    "patience = 30\n",
    "optimizers_tuple = (torch.optim.Adam(GNN_models_tuple[0].parameters(), lr=5e-4 , eps=1e-7),\n",
    "                    torch.optim.Adam(GNN_models_tuple[1].parameters(), lr=2e-3 , eps=1e-7),\n",
    "                    torch.optim.Adam(GNN_models_tuple[2].parameters(), lr=4e-3 , eps=1e-7),\n",
    "                    torch.optim.Adam(combined_model.parameters(), lr=1e-3 , eps=1e-7) )\n",
    "\n",
    "t_func.combined_training(train_loaders_tuple, test_loaders_tuple, GNN_models_tuple, combined_model, loss_mse, optimizers_tuple, epochs, norms_tuple, MIN_VOL_METRICS, patience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea8cb14-5dc6-40cf-b12f-3655e30600a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Scoring\n",
    "\n",
    "Epoch 15:\n",
    "\n",
    "100%|████████████████████████████████████████████████████████████████████████████████| 804/804 [07:13<00:00,  1.85it/s]\n",
    "\n",
    "Train bike : Avg loss: 0.000222 | Start RMSE: 8.30 | Start MAPE: 27.62 % | Stop RMSE: 7.92 | Stop MAPE: 26.77 %\n",
    "Train bike combination : Avg loss: 0.000297 | Start RMSE: 9.51 | Start MAPE: 31.14 % | Stop RMSE: 9.17 | Stop MAPE: 30.61 %\n",
    "Train gtaxi : Avg loss: 0.000132 | Start RMSE: 5.77 | Start MAPE: 27.38 % | Stop RMSE: 3.17 | Stop MAPE: 18.89 %\n",
    "Train gtaxi combination : Avg loss: 0.000297 | Start RMSE: 5.80 | Start MAPE: 27.40 % | Stop RMSE: 3.07 | Stop MAPE: 19.28 %\n",
    "Train ytaxi : Avg loss: 0.000379 | Start RMSE: 28.07 | Start MAPE: 32.86 % | Stop RMSE: 24.09 | Stop MAPE: 31.42 %\n",
    "Train ytaxi combination : Avg loss: 0.000297 | Start RMSE: 31.12 | Start MAPE: 33.18 % | Stop RMSE: 26.26 | Stop MAPE: 31.57 %\n",
    "\n",
    "100%|██████████████████████████████████████████████████████████████████████████████| 1008/1008 [01:29<00:00, 11.26it/s]\n",
    "\n",
    "Test bike : Avg loss: 0.000350 | Start RMSE: 9.17 | Start MAPE: 25.64 % | Stop RMSE: 9.05 | Stop MAPE: 24.94 %\n",
    "Test bike combination : Avg loss: 0.000318 | Start RMSE: 10.25 | Start MAPE: 28.28 % | Stop RMSE: 10.20 | Stop MAPE: 27.91 %\n",
    "Test gtaxi : Avg loss: 0.000080 | Start RMSE: 6.02 | Start MAPE: 27.49 % | Stop RMSE: 2.98 | Stop MAPE: 19.89 %\n",
    "Test gtaxi combination : Avg loss: 0.000318 | Start RMSE: 6.00 | Start MAPE: 26.85 % | Stop RMSE: 2.98 | Stop MAPE: 19.66 %\n",
    "Test ytaxi : Avg loss: 0.000366 | Start RMSE: 30.79 | Start MAPE: 38.88 % | Stop RMSE: 27.54 | Stop MAPE: 37.96 %\n",
    "Test ytaxi combination : Avg loss: 0.000318 | Start RMSE: 30.75 | Start MAPE: 38.13 % | Stop RMSE: 29.38 | Stop MAPE: 37.09 %"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
